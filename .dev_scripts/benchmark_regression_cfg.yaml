model_list:
    inference:
        -   # necessary parameters
            config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w32_coco_256x192.py  # path to the config file
            checkpoint: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth # the config file
            priority: 0 # the priority of the model, 0: core, 1: important, 2: less important, 3: least important

            # optional parameters, if not specified, use the default setting in the .dev_scripts/benchmark_regression.py
            port: 29666 # the port number used to communicate between different GPUs
            gpus: 2 # specify the number of GPUs needed according to the specific task
            gpus_per_node: 2 # the number of GPUs used each computing node
            cpus_per_task: 5 # the number of cpus per task
            partition: openmmlab  # the partition name
            task_name: infer_hrnet_w32_coco_256x192 # the job name shown in slurm
            py_args: # other arguments to run the script tools/test.py
                out: results_hrnet_w32_coco_256x192.json  # output result file
                eval: mAP # evaluation metric, which depends on the dataset, e.g., "mAP" for MSCOCO
                fuse-conv-bn:
                gpu_collect:

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w32_coco_256x192_dark.py
            checkpoint: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192_dark-07f147eb_20200812.pth
            priority: 1

            port: 29667
            gpus: 2
            gpus_per_node: 2
            cpus_per_task: 5
            partition: openmmlab
            task_name: infer_hrnet_w32_coco_256x192_dark
            py_args:
                out: results_hrnet_w32_coco_256x192_dark.json
                eval: mAP

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/mobilenetv2_coco_256x192.py
            checkpoint: https://download.openmmlab.com/mmpose/top_down/mobilenetv2/mobilenetv2_coco_256x192-d1e58e7b_20200727.pth
            priority: 2
            port: 29668
            gpus: 2
            gpus_per_node: 2
            cpus_per_task: 5
            partition: openmmlab
            task_name: infer_mobilenetv2_coco_256x192
            py_args:
                out: results_mobilenetv2_coco_256x192.json
                eval: mAP

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/res50_coco_256x192.py
            checkpoint: https://download.openmmlab.com/mmpose/top_down/resnet/res50_coco_256x192-ec54d7f3_20200709.pth
            priority: 3
            port: 29669
            gpus: 2
            gpus_per_node: 2
            cpus_per_task: 5
            partition: openmmlab
            task_name: infer_res50_coco_256x192
            py_args:
                out: results_res50_coco_256x192.json
                eval: mAP

        -   config: configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py
            checkpoint: https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth
            priority: 1
            port: 29670
            gpus: 2
            gpus_per_node: 2
            cpus_per_task: 5
            partition: openmmlab
            task_name: infer_hrnet_w32_coco_512x512
            py_args:
                out: results_hrnet_w32_coco_512x512.json
                eval: mAP

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/hrnet_w32_mpii_256x256.py
            checkpoint: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_mpii_256x256-6c4f923f_20200812.pth
            priority: 2
            port: 29671
            gpus: 2
            gpus_per_node: 2
            cpus_per_task: 5
            partition: openmmlab
            task_name: infer_hrnet_w32_mpii_256x256

    train:
        -   # necessary parameters
            config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/res50_coco_256x192.py
            priority: 0 # the priority of the model, 0: core, 1: important, 2: less important, 3: least important

            # optional parameters, if not specified, use the default setting in the .dev_scripts/benchmark_regression.py
            port: 29672 # the port number used to communicate between different GPUs
            gpus: 8 # specify the number of GPUs needed according to the specific task
            gpus_per_node: 8 # the number of GPUs used each computing node
            cpus_per_task: 5 # the number of cpus per task
            partition: openmmlab  # the partition name
            task_name: train_res50_coco_256x192 # the job name shown in slurm
            py_args: # other arguments to run the script tools/train.py
                resume-from: # the checkpoint file to resume from
                # override some settings in the used config, the key-value pair
                # in xxx=yyy format, will be merged into config file. For example,
                # '--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'
                cfg-options:
                    model.backbone.depth=18
                    model.backbone.with_cp=True
                    lr_config.warmup_ratio=0.01
                no-validate:
                deterministic:
                autoscale-lr:

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w32_coco_256x192.py
            priority: 1
            port: 29673
            gpus: 8
            gpus_per_node: 8
            cpus_per_task: 5
            partition: openmmlab
            task_name: train_hrnet_w32_coco_256x192
            py_args:
                resume-from:
                cfg-options:

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/mobilenetv2_coco_256x192.py
            priority: 2
            port: 29674
            gpus: 8
            gpus_per_node: 8
            cpus_per_task: 5
            partition: openmmlab
            task_name: train_mobilenetv2_coco_256x192
            py_args:
                resume-from:
                cfg-options:

        -   config: configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/mpii/hrnet_w32_mpii_256x256.py
            priority: 3
            port: 29675
            gpus: 8
            gpus_per_node: 8
            cpus_per_task: 5
            partition: openmmlab
            task_name: train_rnet_w32_mpii_256x256
            py_args:
                resume-from:
                cfg-options:
